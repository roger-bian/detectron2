{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import glob\n",
    "import cv2\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check training statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_folder = 'E:/detectron2/model/screw_v1/'\n",
    "\n",
    "def load_json_arr(json_path):\n",
    "    lines = []\n",
    "    with open(json_path, 'r') as f:\n",
    "        for line in f:\n",
    "            lines.append(json.loads(line))\n",
    "    return lines\n",
    "\n",
    "experiment_metrics = load_json_arr(experiment_folder + '/metrics.json')\n",
    "\n",
    "# total loss\n",
    "total_loss_x = [x['iteration'] for x in experiment_metrics if 'total_loss' in x]\n",
    "total_loss_y = [x['total_loss'] for x in experiment_metrics if 'total_loss' in x]\n",
    "\n",
    "# validation loss\n",
    "validation_loss_x = [x['iteration'] for x in experiment_metrics if 'validation_loss' in x]\n",
    "validation_loss_y = [x['validation_loss'] for x in experiment_metrics if 'validation_loss' in x]\n",
    "\n",
    "# get best validation loss\n",
    "min_val_loss = 99999999\n",
    "for idx, x in enumerate(experiment_metrics):\n",
    "    if 'validation_loss' in x and x['validation_loss'] < min_val_loss:\n",
    "        min_val_loss = x['validation_loss']\n",
    "        i = x['iteration']\n",
    "        min_val_loss_idx = idx\n",
    "print('Best validation loss:')\n",
    "print(f'iteration: {i}')\n",
    "print(f'loss: {min_val_loss}')\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(total_loss_x, total_loss_y)\n",
    "plt.plot(validation_loss_x, validation_loss_y)\n",
    "plt.scatter(i, min_val_loss, color='red', s=50)\n",
    "plt.legend(['total_loss', 'validation_loss'], loc='upper right')\n",
    "plt.ylim(0, 0.6)\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# AP\n",
    "bbox_AP_x = [x['iteration'] for x in experiment_metrics if 'bbox/AP' in x]\n",
    "bbox_AP_y = [x['bbox/AP'] for x in experiment_metrics if 'bbox/AP' in x]\n",
    "\n",
    "\n",
    "# best AP\n",
    "bbox_AP = bbox_AP_y[bbox_AP_x.index(i)]\n",
    "print(f'bbox_AP: {bbox_AP}')\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(bbox_AP_x, bbox_AP_y)\n",
    "plt.scatter(i, bbox_AP, color='red', s=50)\n",
    "plt.legend(['AP'], loc='upper right')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference on one image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARENT_FOLDER = 'E:/detectron2/model/screw_v1/'\n",
    "SELECTED_MODEL = 'model_0001299.pth'\n",
    "IMAGE_PATH = \"E:/paloma/task17/IMG_0064.jpg\"\n",
    "\n",
    "CLASS_NAMES = [\n",
    "    \"screw\",\n",
    "]  # Add your class names here\n",
    "CLASS_COLORS = [\n",
    "    [255, 0, 0],  # Red for class 0\n",
    "    # [0, 0, 255],  # Blue for class 1   # Uncomment if you have more classes\n",
    "]\n",
    "\n",
    "SCORE_THRESH = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to configure the model for inference\n",
    "def setup_inference(config_path, model_weights_path, score_thresh=0.3):\n",
    "    cfg = get_cfg()\n",
    "    cfg.set_new_allowed(True)\n",
    "    cfg.merge_from_file(config_path)\n",
    "    cfg.MODEL.WEIGHTS = os.path.join(model_weights_path)\n",
    "    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = score_thresh  # Minimum score to keep a detection\n",
    "    cfg.MODEL.ROI_HEADS.NMS_THRESH_TEST = 0.5    # IoU threshold for NMS                                                                                                                                                                                                                                                                                                                                                                     \n",
    "    return cfg\n",
    "\n",
    "# Function to perform inference on a single image\n",
    "def inference_on_image(image_path, predictor, metadata=None, score_thresh=0.7):\n",
    "    img = cv2.imread(image_path)\n",
    "    outputs = predictor(img)\n",
    "    instances = outputs[\"instances\"].to(\"cpu\")\n",
    "    \n",
    "    # Visualize results using visualizer\n",
    "    visualizer = Visualizer(img[:, :, ::-1], metadata=metadata, scale=1)\n",
    "    out = visualizer.draw_instance_predictions(instances)\n",
    "    \n",
    "    result_image = cv2.cvtColor(out.get_image(), cv2.COLOR_BGR2RGB)\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    plt.imshow(result_image)\n",
    "    plt.show()\n",
    "\n",
    "    # Visualize by manual drawing on original image\n",
    "    for i in range(len(instances.pred_boxes)):\n",
    "        coords = instances.pred_boxes.tensor[i].int().numpy()\n",
    "\n",
    "        # draw boxes + write text\n",
    "        draw_color = CLASS_COLORS[instances.pred_classes[i]]\n",
    "        text = CLASS_NAMES[instances.pred_classes[i]]\n",
    "        \n",
    "        x_start = coords[0]\n",
    "        y_start = coords[1]\n",
    "        cv2.rectangle(img, (x_start, y_start), (coords[2], coords[3]), draw_color, 2)\n",
    "        \n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        font_scale = .5\n",
    "        font_thickness = 1\n",
    "        text_size, _ = cv2.getTextSize(text, font, font_scale, font_thickness)\n",
    "        text_w, text_h = text_size\n",
    "        cv2.rectangle(img, (x_start, y_start), (x_start + text_w, y_start + text_h + 5), (255, 255, 255), -1)\n",
    "        cv2.putText(img, text, (x_start, y_start + text_h), font, font_scale, draw_color, font_thickness, cv2.LINE_AA)\n",
    "\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "\n",
    "# Paths to your config file and trained model\n",
    "config_path = f\"{PARENT_FOLDER}/config.yaml\"\n",
    "model_weights_path = f\"{PARENT_FOLDER}/{SELECTED_MODEL}\"\n",
    "image_path = IMAGE_PATH\n",
    "\n",
    "\n",
    "# Set up the model for inference\n",
    "cfg = setup_inference(config_path, model_weights_path, score_thresh=SCORE_THRESH)\n",
    "predictor = DefaultPredictor(cfg)\n",
    "    \n",
    "# Perform inference\n",
    "inference_on_image(image_path, predictor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference on directory of images & save to output folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_FOLDER = \"E:/paloma/task17/screw_head/coco/valid_coco/JPEGImages\"  # Folder containing input images\n",
    "OUTPUT_FOLDER = \"E:/detectron2/output/screw_w_valid_0001299\"  # Folder to save output images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform inference and save the results\n",
    "def process_images_in_folder(input_folder, output_folder, predictor, metadata=None):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    \n",
    "    for file_name in os.listdir(input_folder):\n",
    "        file_path = os.path.join(input_folder, file_name)\n",
    "        if os.path.isfile(file_path) and file_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            img = cv2.imread(file_path)\n",
    "            st = time.time()\n",
    "            outputs = predictor(img)\n",
    "            instances = outputs[\"instances\"].to(\"cpu\")\n",
    "            \n",
    "            visualizer = Visualizer(img[:, :, ::-1], metadata=metadata, scale=1)\n",
    "            out = visualizer.draw_instance_predictions(instances)\n",
    "            tt = time.time() - st\n",
    "            print(tt)\n",
    "            result_image = cv2.cvtColor(out.get_image(), cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            output_path = os.path.join(output_folder, f\"result_{file_name}\")\n",
    "            cv2.imwrite(output_path, result_image)\n",
    "            print(f\"Saved result to {output_path}\")\n",
    "\n",
    "# Paths to your config file and trained model\n",
    "config_path = f\"{PARENT_FOLDER}/config.yaml\"\n",
    "model_weights_path = f\"{PARENT_FOLDER}/{SELECTED_MODEL}\"\n",
    "\n",
    "# Set up the model for inference\n",
    "cfg = setup_inference(config_path, model_weights_path, score_thresh=SCORE_THRESH)\n",
    "predictor = DefaultPredictor(cfg)\n",
    "\n",
    "# Process images in the input folder\n",
    "process_images_in_folder(INPUT_FOLDER, OUTPUT_FOLDER, predictor)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "detectron2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
